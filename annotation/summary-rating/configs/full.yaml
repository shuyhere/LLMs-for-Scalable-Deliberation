{
    "port": 8001,

    "server_name": "potato annotator",

    "annotation_task_name": "Summary Rating",

    # Potato will write the annotation file for all annotations to this
    # directory, as well as per-annotator output files and state information
    # necessary to restart annotation.
    "output_annotation_dir": "annotation_output/test/",

    # The output format for the all-annotator data. Allowed formats are:
    # * jsonl
    # * json (same output as jsonl)
    # * csv
    # * tsv
    #
    "output_annotation_format": "csv",

    # If annotators are using a codebook, this will be linked at the top to the
    # instance for easy access
    "annotation_codebook_url": "",  

    "data_files": [
       "data_files/processed/sum_humanstudy_triplet_full_ring.csv"
    ],

    "item_properties": {
        "id_key": "id",
        "text_key": "text",
    },

  #list_as_text is used when the input text is actually a list of texts, usually used for best-worst-scaling
    "list_as_text": {
      "text_list_prefix_type": 'None',
      "horizontal": True,
    },

    "user_config": {

      "allow_all_users": True,

      "users": [  ],
    },

    "prolific": {
      "config_file_path": 'configs/prolific_config.yaml'
    },

    #defining the ways annotators entering the annotation system
    "login": {
       "type": 'prolific',    #can be 'password' or 'url_direct'
       #"url_argument": 'PROLIFIC_PID' # when the login type is set to 'url_direct', 'url_argument' must be setup for a direct url argument login
    },

    #the jumping-to-id function will be disabled if "jumping_to_id_disabled" is True
    "jumping_to_id_disabled": True,

  #the navigation bar will be hidden to the annotators if "hide_navbar" is True
    "hide_navbar": True,

  # define the surveyflow of the system, set up the pages before and after the data annotation page
    "surveyflow": {
      "on": True,
      #"order" : ['pre_annotation', 'prestudy_passed', 'prestudy_failed', 'post_annotation'],
      "order" : ['pre_annotation', 'post_annotation'],
      "pre_annotation": ['surveyflow/intro.jsonl'],
      "post_annotation": ['surveyflow/end.jsonl'],
      # If set, we will automatically generate testing questions similar to the annotation instances, but explicitly ask the annotator to choose one option
      "testing": ['surveyflow/testing.jsonl'],
    },



    "automatic_assignment": {
      #whether do automatic task assignment for annotators, default False.
      "on": True,
      "output_filename": 'task_assignment.json',
      "sampling_strategy": 'ordered',
      "labels_per_instance": 1,
      "instance_per_annotator": 3,
      "test_question_per_annotator": 0, # you must set up the test question in surveyflow to use this function

      "users": [  ],
    },


    # How many seconds do you want the annotators spend on each instance, after
    # that, an alert will be sent per alert_time_each_instance seconds.
    "alert_time_each_instance": 10000000,
    "horizontal_key_bindings": true,

    "annotation_schemes": [
      # First page: Question + Answer (from both pilots)
      {
            "annotation_type": "text",
            "name": "answer",
            "description": "Please share your opinion on the question in 2-3 sentences.",

            # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
            "label_requirement": {"required":True},

            # if you want to use multi-line textbox, turn on the text area and set the desired rows and cols of the textbox
            "textarea": {
              "on": True,
              "rows": 5,
              "cols": 60
            }
            # If true, numbers [1-len(labels)] will be bound to each
            # label. Aannotations with more than 10 are not supported with this
            # simple keybinding and will need to use the full item specification to
            # to bind all labels to keys.
            #"sequential_key_binding": True,
      },

      {
            "annotation_type": "radio",
            "name": "To what extent is your perspective represented in this response?", 
            "description": "To what extent is your perspective represented in this response? (Please select only one option)",
            "labels": [
            "Not represented — summary ignores comment",
            "Slightly represented — little relevant content",
            "Partially represented — main idea but gaps",
            "Mostly represented — most info, minor nuance missing",
            "Fully represented — all info included"
          ],
            "label_requirement": { "required": True },
            # If true, numbers [1-len(labels)] will be bound to each
            # label. Check box annotations with more than 10 are not supported
            # with this simple keybinding and will need to use the full item
            # specification to bind all labels to keys.
            "sequential_key_binding": True,            
      },       

      {
            "annotation_type": "radio",
            "name": "How informative is this summary?", 
            "description": "How informative is this summary? (Please select only one option)",
            "labels": [
              "Not informative — almost no content",
              "Slightly informative — few basic points",
              "Moderately informative — some important details",
              "Very informative — most details included",
              "Extremely informative — highly detailed and comprehensive"
            ],
            "label_requirement": { "required": True },
            # If true, numbers [1-len(labels)] will be bound to each
            # label. Check box annotations with more than 10 are not supported
            # with this simple keybinding and will need to use the full item
            # specification to bind all labels to keys.
            "sequential_key_binding": True,            
      }, 

      {
            "annotation_type": "radio",
            "name": "Do you think this summary presents a neutral and balanced view of the issue?", 
            "description": "Do you think this summary presents a neutral and balanced view of the issue? (Please select only one option)",
            "labels": [
              "Very non-neutral — strongly one-sided",
              "Somewhat non-neutral — noticeable tilt",
              "Moderately neutral — mix of neutrality and tilt",
              "Fairly neutral — mostly impartial",
              "Completely neutral — fully impartial"
            ],
            "label_requirement": { "required": True },
            # If true, numbers [1-len(labels)] will be bound to each
            # label. Check box annotations with more than 10 are not supported
            # with this simple keybinding and will need to use the full item
            # specification to bind all labels to keys.
            "sequential_key_binding": True,            
      }, 
      {
        "annotation_type": "radio",

        # This name gets used in reporting the annotation results
        "name": "Would you approve of this summary being used by the policy makers to make decisions relevant to the issue? (Please select only one option)",

        # This text is shown to the user and can be a longer statement
        "description": "Would you approve of this summary being used by the policy makers to make decisions relevant to the issue? (Please select only one option)",

        # The min and max labels are text shown at each end of the scale
        "labels": [
          "Strongly disapprove",
          "Disapprove",
          "Neutral",
          "Approve",
          "Strongly approve"
        ],
        # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
        "label_requirement": { "required": True },
        # How many scale points to show
        "sequential_key_binding": True,

        # If true, keys [1-size] will be bound to scale responses. Likert
        # scales larger than 10 are not supported with this simple
        # keybinding and will need to use the full item specification to
        # bind all scale points to keys.
        #"sequential_key_binding": True,
      },

      # Third page: Comparison tasks (from pilot_pair.yaml)
      {
        "annotation_type": "radio",

        # This name gets used in reporting the annotation results
        "name": "Which summary is more representative of your perspective? (Please select only one option)",

        # This text is shown to the user and can be a longer statement
        "description": "Which summary is more representative of your perspective? (Please select only one option)",

        # The min and max labels are text shown at each end of the scale
        "labels": [
          "A much more representative",
          "A slightly more representative",
          "Both about the same",
          "B slightly more representative",
          "B much more representative"
        ],
        # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
        "label_requirement": { "required": True },
        # How many scale points to show
        "sequential_key_binding": True,

        # If true, keys [1-size] will be bound to scale responses. Likert
        # scales larger than 10 are not supported with this simple
        # keybinding and will need to use the full item specification to
        # bind all scale points to keys.
        #"sequential_key_binding": True,
      },
      {
        "annotation_type": "radio",

        # This name gets used in reporting the annotation results
        "name": "Which summary is more informative? (Please select only one option)",

        # This text is shown to the user and can be a longer statement
        "description": "Which summary is more informative? (Please select only one option)",

        # The min and max labels are text shown at each end of the scale
        "labels": [
          "A much more informative",
          "A slightly more informative",
          "Both about the same",
          "B slightly more informative",
          "B much more informative"
        ],
        # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
        "label_requirement": { "required": True },
        # How many scale points to show
        "sequential_key_binding": True,

        # If true, keys [1-size] will be bound to scale responses. Likert
        # scales larger than 10 are not supported with this simple
        # keybinding and will need to use the full item specification to
        # bind all scale points to keys.
        #"sequential_key_binding": True,
      },
      {
        "annotation_type": "radio",

        # This name gets used in reporting the annotation results
        "name": "Which summary presents a more neutral and balanced view of the issue? (Please select only one option)",

        # This text is shown to the user and can be a longer statement
        "description": "Which summary presents a more neutral and balanced view of the issue? (Please select only one option)",

        # The min and max labels are text shown at each end of the scale
        "labels": [
          "A much more neutral and balanced",
          "A slightly more neutral and balanced",
          "Both about the same",
          "B slightly more neutral and balanced",
          "B much more neutral and balanced"
        ],
        # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
        "label_requirement": { "required": True },
        # How many scale points to show
        "sequential_key_binding": True,

        # If true, keys [1-size] will be bound to scale responses. Likert
        # scales larger than 10 are not supported with this simple
        # keybinding and will need to use the full item specification to
        # bind all scale points to keys.
        #"sequential_key_binding": True,
      },
      {
        "annotation_type": "radio",

        # This name gets used in reporting the annotation results
        "name": "Which summary would you prefer of being used by the policy makers to make decisions relevant to the issue? (Please select only one option)",

        # This text is shown to the user and can be a longer statement
        "description": "Which summary would you prefer of being used by the policy makers to make decisions relevant to the issue? (Please select only one option)",

        # The min and max labels are text shown at each end of the scale
        "labels": [
          "A much more preferred",
          "A slightly more preferred",
          "Both about the same",
          "B slightly more preferred",
          "B much more preferred"
        ],
        # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
        "label_requirement": { "required": True },
        # How many scale points to show
        "sequential_key_binding": True,

        # If true, keys [1-size] will be bound to scale responses. Likert
        # scales larger than 10 are not supported with this simple
        # keybinding and will need to use the full item specification to
        # bind all labels to keys.
        #"sequential_key_binding": True,
      },
      

    ],

    # The html that changes the visualiztation for your task. Change this file
    # to influence the layout and description of your task. This is not a full
    # HTML page, just the piece that does lays out your task's pieces
    #"html_layout": "templates/examples/fixed_keybinding_layout.html",
    "html_layout": "templates/layout.html",

    "surveyflow_html_layout": "templates/survey_layout.html",

    # The core UI files for Potato. You should not need to change these normally.
    #
    # Exceptions to this might include:
    # 1) You want to add custom CSS/fonts to style your task
    # 2) Your layout requires additional JS/assets to render
    # 3) You want to support additional keybinding magic
    #
    # if you want to use your own template,
    # please replace the string as a path to the template
    "base_html_template": "templates/base_template.html",
    "header_file": "templates/header.html",

    # This is where the actual HTML files will be generated
    "site_dir": "default"

}
