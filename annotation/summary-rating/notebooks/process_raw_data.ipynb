{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import markdown\n",
    "from markdown.extensions import codehilite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_files/raw/summaries_V0903_for_humanstudy_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deepseek-chat', 'gemini-2.5-pro', 'gpt-5', 'qwen3-32b',\n",
       "       'web-rev-claude-opus-4-20250514'], dtype=object)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>question</th>\n",
       "      <th>summary</th>\n",
       "      <th>model</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>comments</th>\n",
       "      <th>num_samples_group</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>source_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be44d0160fd1ec36</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>Here is a summary of the comments provided:\\n\\...</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>70</td>\n",
       "      <td>0: I am pretty conflicted, but I think overall...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>results/human_judgement/gemini-2.5-pro/70/Bina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c5e28aaa30501e42</td>\n",
       "      <td>Binary-Online-Identity-Policies</td>\n",
       "      <td>Do you support requiring real-name registratio...</td>\n",
       "      <td>Overall, comments reflect a divided perspectiv...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>90</td>\n",
       "      <td>0: No I don’t support it. I think it’s fine to...</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>Binary-Online-Identity-Policies</td>\n",
       "      <td>results/human_judgement/deepseek-chat/90/Binar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ad06843babdcceca</td>\n",
       "      <td>Binary-Online-Identity-Policies</td>\n",
       "      <td>Do you support requiring real-name registratio...</td>\n",
       "      <td>## Summary of Comments on Real-Name Registrati...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>90</td>\n",
       "      <td>0: No I don’t support it. I think it’s fine to...</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary-Online-Identity-Policies</td>\n",
       "      <td>results/human_judgement/web-rev-claude-opus-4-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e38ed9ce8b9e3220</td>\n",
       "      <td>Binary-Tariff-Policy</td>\n",
       "      <td>Do you think the current tariff policy under t...</td>\n",
       "      <td>The comments reflect a wide range of opinions ...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>90</td>\n",
       "      <td>0: i think that it will have a negative impact...</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary-Tariff-Policy</td>\n",
       "      <td>results/human_judgement/deepseek-chat/90/Binar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5eb7a59774dbb009</td>\n",
       "      <td>Binary-Tariff-Policy</td>\n",
       "      <td>Do you think the current tariff policy under t...</td>\n",
       "      <td>The comments on the impact of the Trump admini...</td>\n",
       "      <td>qwen3-32b</td>\n",
       "      <td>90</td>\n",
       "      <td>0: i think that it will have a negative impact...</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary-Tariff-Policy</td>\n",
       "      <td>results/human_judgement/qwen3-32b/90/Binary-Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>43386f89462d5edf</td>\n",
       "      <td>Binary-Vaccination-Policy</td>\n",
       "      <td>Do you support the government having the autho...</td>\n",
       "      <td>Based on the comments provided, opinions are d...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>10</td>\n",
       "      <td>0: I do not. I think that people can be highly...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Binary-Vaccination-Policy</td>\n",
       "      <td>results/human_judgement/deepseek-chat/10/Binar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>4ed4077a8fc1a871</td>\n",
       "      <td>Openqa-AI-changes-human-life</td>\n",
       "      <td>How has AI changed your life? Please answer br...</td>\n",
       "      <td>## Summary of Comments on AI's Impact on Daily...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>10</td>\n",
       "      <td>0: Al changed my life by making my daily tasks...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Openqa-AI-changes-human-life</td>\n",
       "      <td>results/human_judgement/web-rev-claude-opus-4-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>41fbf63fa33dc720</td>\n",
       "      <td>Openqa-Updates-of-electronic-products</td>\n",
       "      <td>What is your opinion on the rapid update cycle...</td>\n",
       "      <td>Overall summary of the comments:\\n\\n- Sentimen...</td>\n",
       "      <td>gpt-5</td>\n",
       "      <td>50</td>\n",
       "      <td>0: The rapid updates cycle electronic products...</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Openqa-Updates-of-electronic-products</td>\n",
       "      <td>results/human_judgement/gpt-5/50/Openqa-Update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>74f5e06827c57f1c</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>The comments reflect a strong humanitarian sen...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>50</td>\n",
       "      <td>0: I am pretty conflicted, but I think overall...</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>results/human_judgement/deepseek-chat/50/Binar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1dd8a02edf92e5b0</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>## Summary of Public Comments on Accepting Ref...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>50</td>\n",
       "      <td>0: I am pretty conflicted, but I think overall...</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Binary-Refugee-Policies</td>\n",
       "      <td>results/human_judgement/web-rev-claude-opus-4-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                  topic  \\\n",
       "0    be44d0160fd1ec36                Binary-Refugee-Policies   \n",
       "1    c5e28aaa30501e42        Binary-Online-Identity-Policies   \n",
       "2    ad06843babdcceca        Binary-Online-Identity-Policies   \n",
       "3    e38ed9ce8b9e3220                   Binary-Tariff-Policy   \n",
       "4    5eb7a59774dbb009                   Binary-Tariff-Policy   \n",
       "..                ...                                    ...   \n",
       "745  43386f89462d5edf              Binary-Vaccination-Policy   \n",
       "746  4ed4077a8fc1a871           Openqa-AI-changes-human-life   \n",
       "747  41fbf63fa33dc720  Openqa-Updates-of-electronic-products   \n",
       "748  74f5e06827c57f1c                Binary-Refugee-Policies   \n",
       "749  1dd8a02edf92e5b0                Binary-Refugee-Policies   \n",
       "\n",
       "                                              question  \\\n",
       "0    Do you support the government accepting more r...   \n",
       "1    Do you support requiring real-name registratio...   \n",
       "2    Do you support requiring real-name registratio...   \n",
       "3    Do you think the current tariff policy under t...   \n",
       "4    Do you think the current tariff policy under t...   \n",
       "..                                                 ...   \n",
       "745  Do you support the government having the autho...   \n",
       "746  How has AI changed your life? Please answer br...   \n",
       "747  What is your opinion on the rapid update cycle...   \n",
       "748  Do you support the government accepting more r...   \n",
       "749  Do you support the government accepting more r...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Here is a summary of the comments provided:\\n\\...   \n",
       "1    Overall, comments reflect a divided perspectiv...   \n",
       "2    ## Summary of Comments on Real-Name Registrati...   \n",
       "3    The comments reflect a wide range of opinions ...   \n",
       "4    The comments on the impact of the Trump admini...   \n",
       "..                                                 ...   \n",
       "745  Based on the comments provided, opinions are d...   \n",
       "746  ## Summary of Comments on AI's Impact on Daily...   \n",
       "747  Overall summary of the comments:\\n\\n- Sentimen...   \n",
       "748  The comments reflect a strong humanitarian sen...   \n",
       "749  ## Summary of Public Comments on Accepting Ref...   \n",
       "\n",
       "                              model  comment_num  \\\n",
       "0                    gemini-2.5-pro           70   \n",
       "1                     deepseek-chat           90   \n",
       "2    web-rev-claude-opus-4-20250514           90   \n",
       "3                     deepseek-chat           90   \n",
       "4                         qwen3-32b           90   \n",
       "..                              ...          ...   \n",
       "745                   deepseek-chat           10   \n",
       "746  web-rev-claude-opus-4-20250514           10   \n",
       "747                           gpt-5           50   \n",
       "748                   deepseek-chat           50   \n",
       "749  web-rev-claude-opus-4-20250514           50   \n",
       "\n",
       "                                              comments  num_samples_group  \\\n",
       "0    0: I am pretty conflicted, but I think overall...                 70   \n",
       "1    0: No I don’t support it. I think it’s fine to...                 90   \n",
       "2    0: No I don’t support it. I think it’s fine to...                 90   \n",
       "3    0: i think that it will have a negative impact...                 90   \n",
       "4    0: i think that it will have a negative impact...                 90   \n",
       "..                                                 ...                ...   \n",
       "745  0: I do not. I think that people can be highly...                 10   \n",
       "746  0: Al changed my life by making my daily tasks...                 10   \n",
       "747  0: The rapid updates cycle electronic products...                 50   \n",
       "748  0: I am pretty conflicted, but I think overall...                 50   \n",
       "749  0: I am pretty conflicted, but I think overall...                 50   \n",
       "\n",
       "     sample_id                           dataset_name  \\\n",
       "0            1                Binary-Refugee-Policies   \n",
       "1            3        Binary-Online-Identity-Policies   \n",
       "2            2        Binary-Online-Identity-Policies   \n",
       "3            2                   Binary-Tariff-Policy   \n",
       "4            2                   Binary-Tariff-Policy   \n",
       "..         ...                                    ...   \n",
       "745          1              Binary-Vaccination-Policy   \n",
       "746          3           Openqa-AI-changes-human-life   \n",
       "747          1  Openqa-Updates-of-electronic-products   \n",
       "748          3                Binary-Refugee-Policies   \n",
       "749          1                Binary-Refugee-Policies   \n",
       "\n",
       "                                           source_path  \n",
       "0    results/human_judgement/gemini-2.5-pro/70/Bina...  \n",
       "1    results/human_judgement/deepseek-chat/90/Binar...  \n",
       "2    results/human_judgement/web-rev-claude-opus-4-...  \n",
       "3    results/human_judgement/deepseek-chat/90/Binar...  \n",
       "4    results/human_judgement/qwen3-32b/90/Binary-Ta...  \n",
       "..                                                 ...  \n",
       "745  results/human_judgement/deepseek-chat/10/Binar...  \n",
       "746  results/human_judgement/web-rev-claude-opus-4-...  \n",
       "747  results/human_judgement/gpt-5/50/Openqa-Update...  \n",
       "748  results/human_judgement/deepseek-chat/50/Binar...  \n",
       "749  results/human_judgement/web-rev-claude-opus-4-...  \n",
       "\n",
       "[750 rows x 11 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Process the dataframe into the desired format\n",
    "processed_data = []\n",
    "\n",
    "for i, (_, row) in enumerate(df.iterrows()):\n",
    "    raw_id = row['id']\n",
    "    question = row['question']\n",
    "    summary = row['summary']\n",
    "    \n",
    "    # Add a row for the question\n",
    "    question_entry = {\n",
    "        \"id\": f\"{raw_id}_question\",\n",
    "        \"raw_id\": raw_id,\n",
    "        \"question\": question,\n",
    "        \"text\": '[Question]' + question.replace(\"\\n\", \"<br>\").replace(\" Please answer briefly in 2–3 sentences.\", \"\").replace(\"Please answer briefly in 1–2 sentences.\", \"\"),\n",
    "        \"model\": row['model'],\n",
    "        \"summary_length\": row.get('summary_length', None)\n",
    "    }\n",
    "    processed_data.append(question_entry)\n",
    "    \n",
    "    # Add a row for the summary (convert markdown to HTML using markdown package)\n",
    "    summary_html = markdown.markdown(summary, extensions=['extra', 'codehilite'])\n",
    "    summary_entry = {\n",
    "        \"id\": f\"{raw_id}_summary\",\n",
    "        \"raw_id\": raw_id,\n",
    "        \"question\": question,\n",
    "        \"text\": \"<h4>Below is a summary of people's opinions on the issue.</h4><hr>\" + summary_html,\n",
    "        \"model\": row['model'],\n",
    "        \"summary_length\": row.get('summary_length', None)\n",
    "    }\n",
    "    processed_data.append(summary_entry)\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_id</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>model</th>\n",
       "      <th>summary_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be44d0160fd1ec36_question</td>\n",
       "      <td>be44d0160fd1ec36</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>[Question]Do you support the government accept...</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be44d0160fd1ec36_summary</td>\n",
       "      <td>be44d0160fd1ec36</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>&lt;h4&gt;Below is a summary of people's opinions on...</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5e28aaa30501e42_question</td>\n",
       "      <td>c5e28aaa30501e42</td>\n",
       "      <td>Do you support requiring real-name registratio...</td>\n",
       "      <td>[Question]Do you support requiring real-name r...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c5e28aaa30501e42_summary</td>\n",
       "      <td>c5e28aaa30501e42</td>\n",
       "      <td>Do you support requiring real-name registratio...</td>\n",
       "      <td>&lt;h4&gt;Below is a summary of people's opinions on...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad06843babdcceca_question</td>\n",
       "      <td>ad06843babdcceca</td>\n",
       "      <td>Do you support requiring real-name registratio...</td>\n",
       "      <td>[Question]Do you support requiring real-name r...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>41fbf63fa33dc720_summary</td>\n",
       "      <td>41fbf63fa33dc720</td>\n",
       "      <td>What is your opinion on the rapid update cycle...</td>\n",
       "      <td>&lt;h4&gt;Below is a summary of people's opinions on...</td>\n",
       "      <td>gpt-5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>74f5e06827c57f1c_question</td>\n",
       "      <td>74f5e06827c57f1c</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>[Question]Do you support the government accept...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>74f5e06827c57f1c_summary</td>\n",
       "      <td>74f5e06827c57f1c</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>&lt;h4&gt;Below is a summary of people's opinions on...</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1dd8a02edf92e5b0_question</td>\n",
       "      <td>1dd8a02edf92e5b0</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>[Question]Do you support the government accept...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1dd8a02edf92e5b0_summary</td>\n",
       "      <td>1dd8a02edf92e5b0</td>\n",
       "      <td>Do you support the government accepting more r...</td>\n",
       "      <td>&lt;h4&gt;Below is a summary of people's opinions on...</td>\n",
       "      <td>web-rev-claude-opus-4-20250514</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id            raw_id  \\\n",
       "0     be44d0160fd1ec36_question  be44d0160fd1ec36   \n",
       "1      be44d0160fd1ec36_summary  be44d0160fd1ec36   \n",
       "2     c5e28aaa30501e42_question  c5e28aaa30501e42   \n",
       "3      c5e28aaa30501e42_summary  c5e28aaa30501e42   \n",
       "4     ad06843babdcceca_question  ad06843babdcceca   \n",
       "...                         ...               ...   \n",
       "1495   41fbf63fa33dc720_summary  41fbf63fa33dc720   \n",
       "1496  74f5e06827c57f1c_question  74f5e06827c57f1c   \n",
       "1497   74f5e06827c57f1c_summary  74f5e06827c57f1c   \n",
       "1498  1dd8a02edf92e5b0_question  1dd8a02edf92e5b0   \n",
       "1499   1dd8a02edf92e5b0_summary  1dd8a02edf92e5b0   \n",
       "\n",
       "                                               question  \\\n",
       "0     Do you support the government accepting more r...   \n",
       "1     Do you support the government accepting more r...   \n",
       "2     Do you support requiring real-name registratio...   \n",
       "3     Do you support requiring real-name registratio...   \n",
       "4     Do you support requiring real-name registratio...   \n",
       "...                                                 ...   \n",
       "1495  What is your opinion on the rapid update cycle...   \n",
       "1496  Do you support the government accepting more r...   \n",
       "1497  Do you support the government accepting more r...   \n",
       "1498  Do you support the government accepting more r...   \n",
       "1499  Do you support the government accepting more r...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     [Question]Do you support the government accept...   \n",
       "1     <h4>Below is a summary of people's opinions on...   \n",
       "2     [Question]Do you support requiring real-name r...   \n",
       "3     <h4>Below is a summary of people's opinions on...   \n",
       "4     [Question]Do you support requiring real-name r...   \n",
       "...                                                 ...   \n",
       "1495  <h4>Below is a summary of people's opinions on...   \n",
       "1496  [Question]Do you support the government accept...   \n",
       "1497  <h4>Below is a summary of people's opinions on...   \n",
       "1498  [Question]Do you support the government accept...   \n",
       "1499  <h4>Below is a summary of people's opinions on...   \n",
       "\n",
       "                               model summary_length  \n",
       "0                     gemini-2.5-pro           None  \n",
       "1                     gemini-2.5-pro           None  \n",
       "2                      deepseek-chat           None  \n",
       "3                      deepseek-chat           None  \n",
       "4     web-rev-claude-opus-4-20250514           None  \n",
       "...                              ...            ...  \n",
       "1495                           gpt-5           None  \n",
       "1496                   deepseek-chat           None  \n",
       "1497                   deepseek-chat           None  \n",
       "1498  web-rev-claude-opus-4-20250514           None  \n",
       "1499  web-rev-claude-opus-4-20250514           None  \n",
       "\n",
       "[1500 rows x 6 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "[Question]What is your opinion on the rapid update cycle of electronic products, especially smartphones?                                                            75\n",
       "[Question]How has AI changed your life?                                                                                                                             75\n",
       "[Question]What is your opinion on internet influencers (e.g., streamers, bloggers, short video creators) increasingly becoming a recognized profession?             75\n",
       "[Question]Do you support the government accepting more refugees fleeing war or persecution?                                                                         75\n",
       "[Question]Do you support requiring real-name registration on social media platforms, where users must register and post under their real identity?                  75\n",
       "[Question]What is your opinion on tipping, and if given the chance, how would you improve or change the current tipping system?                                     75\n",
       "[Question]Do you think the current tariff policy under the Trump administration will have a positive or negative impact on the overall U.S. economy and society?    75\n",
       "[Question]Do you support the government provide basic health insurance for everyone?                                                                                75\n",
       "[Question]What are your thoughts on Trump’s decision to cut academic funding?                                                                                       75\n",
       "[Question]Do you support the government having the authority to enforce vaccination and quarantine measures during severe epidemics?                                75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['text'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in df: 750\n",
      "Unique questions: 10\n",
      "Unique models: 5\n",
      "Unique num_samples_group: 5\n",
      "\n",
      "Group sizes (question, num_samples_group):\n",
      "count    50.0\n",
      "mean     15.0\n",
      "std       0.0\n",
      "min      15.0\n",
      "25%      15.0\n",
      "50%      15.0\n",
      "75%      15.0\n",
      "max      15.0\n",
      "dtype: float64\n",
      "\n",
      "First few groups:\n",
      "question                                                                                                                                                                          num_samples_group\n",
      "Do you support requiring real-name registration on social media platforms, where users must register and post under their real identity? Please answer briefly in 2–3 sentences.  10                   15\n",
      "                                                                                                                                                                                  30                   15\n",
      "                                                                                                                                                                                  50                   15\n",
      "                                                                                                                                                                                  70                   15\n",
      "                                                                                                                                                                                  90                   15\n",
      "Do you support the government accepting more refugees fleeing war or persecution? Please answer briefly in 2–3 sentences.                                                         10                   15\n",
      "                                                                                                                                                                                  30                   15\n",
      "                                                                                                                                                                                  50                   15\n",
      "                                                                                                                                                                                  70                   15\n",
      "                                                                                                                                                                                  90                   15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data structure before processing pairs\n",
    "print(\"Total rows in df:\", len(df))\n",
    "print(\"Unique questions:\", df['question'].nunique())\n",
    "print(\"Unique models:\", df['model'].nunique())\n",
    "print(\"Unique num_samples_group:\", df['num_samples_group'].nunique())\n",
    "\n",
    "# Check grouping structure\n",
    "group_sizes = df.groupby(['question', 'num_samples_group']).size()\n",
    "print(\"\\nGroup sizes (question, num_samples_group):\")\n",
    "print(group_sizes.describe())\n",
    "print(\"\\nFirst few groups:\")\n",
    "print(group_sizes.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('../data_files/processed/sum_humanstudy_rating_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total groups to process: 50\n",
      "Processing group: question='Do you support requiring real-name registration on...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support requiring real-name registration on...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support requiring real-name registration on...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support requiring real-name registration on...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support requiring real-name registration on...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government accepting more refug...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government accepting more refug...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government accepting more refug...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government accepting more refug...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government accepting more refug...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government having the authority...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government having the authority...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government having the authority...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government having the authority...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government having the authority...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government provide basic health...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government provide basic health...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government provide basic health...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government provide basic health...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you support the government provide basic health...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you think the current tariff policy under the T...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you think the current tariff policy under the T...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you think the current tariff policy under the T...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you think the current tariff policy under the T...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='Do you think the current tariff policy under the T...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='How has AI changed your life? Please answer briefl...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='How has AI changed your life? Please answer briefl...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='How has AI changed your life? Please answer briefl...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='How has AI changed your life? Please answer briefl...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='How has AI changed your life? Please answer briefl...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What are your thoughts on Trump’s decision to cut ...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What are your thoughts on Trump’s decision to cut ...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What are your thoughts on Trump’s decision to cut ...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What are your thoughts on Trump’s decision to cut ...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What are your thoughts on Trump’s decision to cut ...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on internet influencers (e.g....', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on internet influencers (e.g....', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on internet influencers (e.g....', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on internet influencers (e.g....', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on internet influencers (e.g....', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on the rapid update cycle of ...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on the rapid update cycle of ...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on the rapid update cycle of ...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on the rapid update cycle of ...', num_samples_group=70, size=15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on the rapid update cycle of ...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on tipping, and if given the ...', num_samples_group=10, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on tipping, and if given the ...', num_samples_group=30, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on tipping, and if given the ...', num_samples_group=50, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on tipping, and if given the ...', num_samples_group=70, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "Processing group: question='What is your opinion on tipping, and if given the ...', num_samples_group=90, size=15\n",
      "  Created 45 pairs for this group\n",
      "  Each summary comparison count: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "\n",
      "Final statistics:\n",
      "Total processed_pair_data entries: 4500\n",
      "Total question entries: 2250\n",
      "Total pair entries: 2250\n",
      "Expected pairs per group (15 summaries, min 6 comparisons each): ~45\n",
      "Expected total pairs for all groups: ~2250\n"
     ]
    }
   ],
   "source": [
    "# Configuration for pairwise comparisons\n",
    "MIN_COMPARISONS_PER_SUMMARY = 6  # Each summary should be compared at least N times\n",
    "\n",
    "# Process the dataframe into the desired format\n",
    "processed_pair_data = []\n",
    "\n",
    "# Group summaries by question AND num_samples_group to create pairs\n",
    "# Only summaries with the same input size should be compared\n",
    "# Expected: 5 models × 3 resamples = 15 summaries per group\n",
    "question_sample_groups = df.groupby(['question', 'num_samples_group'])\n",
    "\n",
    "print(f\"Total groups to process: {len(question_sample_groups)}\")\n",
    "\n",
    "for (question, num_samples_group), group in question_sample_groups:\n",
    "    print(f\"Processing group: question='{question[:50]}...', num_samples_group={num_samples_group}, size={len(group)}\")\n",
    "    \n",
    "    # Verify we have the expected number of summaries (should be 15: 5 models × 3 resamples)\n",
    "    if len(group) != 15:\n",
    "        print(f\"  WARNING: Expected 15 summaries, got {len(group)}\")\n",
    "        print(f\"  Models in group: {group['model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Get all summaries for this group\n",
    "    summaries = list(group.iterrows())\n",
    "    \n",
    "    # Generate pairs with more balanced comparison distribution\n",
    "    pairs_created = []\n",
    "    summary_counts = {i: 0 for i in range(len(summaries))}\n",
    "    \n",
    "    # Create all possible pairs\n",
    "    from itertools import combinations\n",
    "    all_pairs = list(combinations(range(len(summaries)), 2))\n",
    "    \n",
    "    # Configuration for balanced pairing\n",
    "    MAX_COMPARISONS_PER_SUMMARY = MIN_COMPARISONS_PER_SUMMARY + 3  # Allow some flexibility (6-9 comparisons)\n",
    "    \n",
    "    # Improved priority function that considers both minimum requirement and balance\n",
    "    def balanced_pair_priority(pair_indices):\n",
    "        i, j = pair_indices\n",
    "        count_i, count_j = summary_counts[i], summary_counts[j]\n",
    "        \n",
    "        # Prioritize pairs where both summaries are below minimum\n",
    "        both_below_min = (count_i < MIN_COMPARISONS_PER_SUMMARY) and (count_j < MIN_COMPARISONS_PER_SUMMARY)\n",
    "        one_below_min = (count_i < MIN_COMPARISONS_PER_SUMMARY) or (count_j < MIN_COMPARISONS_PER_SUMMARY)\n",
    "        \n",
    "        # Calculate balance score (lower is better)\n",
    "        max_count = max(count_i, count_j)\n",
    "        min_count = min(count_i, count_j)\n",
    "        sum_count = count_i + count_j\n",
    "        \n",
    "        if both_below_min:\n",
    "            return (0, sum_count, max_count - min_count)  # Highest priority\n",
    "        elif one_below_min:\n",
    "            return (1, sum_count, max_count - min_count)  # Medium priority\n",
    "        else:\n",
    "            return (2, sum_count, max_count - min_count)  # Lowest priority\n",
    "    \n",
    "    # Keep adding pairs with balanced approach\n",
    "    while any(count < MIN_COMPARISONS_PER_SUMMARY for count in summary_counts.values()) and all_pairs:\n",
    "        # Filter out pairs that would exceed maximum comparisons\n",
    "        valid_pairs = [\n",
    "            pair for pair in all_pairs \n",
    "            if summary_counts[pair[0]] < MAX_COMPARISONS_PER_SUMMARY \n",
    "            and summary_counts[pair[1]] < MAX_COMPARISONS_PER_SUMMARY\n",
    "        ]\n",
    "        \n",
    "        if not valid_pairs:\n",
    "            # If no valid pairs, allow exceeding max for summaries still below minimum\n",
    "            valid_pairs = [\n",
    "                pair for pair in all_pairs\n",
    "                if (summary_counts[pair[0]] < MIN_COMPARISONS_PER_SUMMARY \n",
    "                    or summary_counts[pair[1]] < MIN_COMPARISONS_PER_SUMMARY)\n",
    "            ]\n",
    "        \n",
    "        if not valid_pairs:\n",
    "            break\n",
    "            \n",
    "        # Sort pairs by balanced priority\n",
    "        valid_pairs.sort(key=balanced_pair_priority)\n",
    "        \n",
    "        # Take the best pair\n",
    "        pair_indices = valid_pairs[0]\n",
    "        all_pairs.remove(pair_indices)\n",
    "        i, j = pair_indices\n",
    "        \n",
    "        # Add this pair\n",
    "        pairs_created.append(pair_indices)\n",
    "        summary_counts[i] += 1\n",
    "        summary_counts[j] += 1\n",
    "    \n",
    "    # Create comparison entries for each pair\n",
    "    for pair_idx, (i, j) in enumerate(pairs_created):\n",
    "        _, row_a = summaries[i]\n",
    "        _, row_b = summaries[j]\n",
    "        \n",
    "        # Add a unique question entry before each pair\n",
    "        question_entry = {\n",
    "            \"id\": f\"{row_a['id']}_{row_b['id']}_pair_{pair_idx}_question\",\n",
    "            \"raw_id\": f\"{row_a['id']}_{row_b['id']}_pair_{pair_idx}\",\n",
    "            \"question\": question,\n",
    "            \"text\": '<h3>[Question]</h3>' + '<h4>' + question.replace(\"\\n\", \"<br>\").replace(\" Please answer briefly in 2–3 sentences.\", \"\").replace(\"Please answer briefly in 1–2 sentences.\", \"\") + '</h4>',\n",
    "            \"model\": \"question\",\n",
    "            \"num_samples_group\": num_samples_group,\n",
    "            \"summary_length\": None\n",
    "        }\n",
    "        processed_pair_data.append(question_entry)\n",
    "        \n",
    "        # Convert summaries to HTML with smaller headers\n",
    "        summary_a_html = markdown.markdown(row_a['summary'], extensions=['extra', 'codehilite'])\n",
    "        summary_b_html = markdown.markdown(row_b['summary'], extensions=['extra', 'codehilite'])\n",
    "        \n",
    "        # Make headers smaller by replacing h1-h3 with h4-h6\n",
    "        import re\n",
    "        summary_a_html = re.sub(r'<h1>', '<h4>', summary_a_html)\n",
    "        summary_a_html = re.sub(r'</h1>', '</h4>', summary_a_html)\n",
    "        summary_a_html = re.sub(r'<h2>', '<h5>', summary_a_html)\n",
    "        summary_a_html = re.sub(r'</h2>', '</h5>', summary_a_html)\n",
    "        summary_a_html = re.sub(r'<h3>', '<h6>', summary_a_html)\n",
    "        summary_a_html = re.sub(r'</h3>', '</h6>', summary_a_html)\n",
    "        \n",
    "        summary_b_html = re.sub(r'<h1>', '<h4>', summary_b_html)\n",
    "        summary_b_html = re.sub(r'</h1>', '</h4>', summary_b_html)\n",
    "        summary_b_html = re.sub(r'<h2>', '<h5>', summary_b_html)\n",
    "        summary_b_html = re.sub(r'</h2>', '</h5>', summary_b_html)\n",
    "        summary_b_html = re.sub(r'<h3>', '<h6>', summary_b_html)\n",
    "        summary_b_html = re.sub(r'</h3>', '</h6>', summary_b_html)\n",
    "        \n",
    "        # Create HTML layout for pairwise comparison with separate scrollbars\n",
    "        comparison_html = f\"\"\"\n",
    "        <div style=\"display: flex; gap: 20px;\">\n",
    "            <div style=\"flex: 1; border: 1px solid #ccc; padding: 15px; border-radius: 5px;\">\n",
    "                <h4 style=\"margin-top: 0; color: #2c5aa0;\">Summary A</h4>\n",
    "                <div style=\"max-height: 800px; overflow-y: auto; padding-right: 10px;\">\n",
    "                    {summary_a_html}\n",
    "                </div>\n",
    "            </div>\n",
    "            <div style=\"flex: 1; border: 1px solid #ccc; padding: 15px; border-radius: 5px;\">\n",
    "                <h4 style=\"margin-top: 0; color: #2c5aa0;\">Summary B</h4>\n",
    "                <div style=\"max-height: 800px; overflow-y: auto; padding-right: 10px;\">\n",
    "                    {summary_b_html}\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        pair_entry = {\n",
    "            \"id\": f\"{row_a['id']}_{row_b['id']}_pair_{pair_idx}\",\n",
    "            \"raw_id\": f\"{row_a['id']}_{row_b['id']}\",\n",
    "            \"question\": question,\n",
    "            \"text\": \"<h4>Two summaries of opinions are shown below. Read carefully and answer according to your prior opinion. Both are scrollable.</h4><hr>\" + comparison_html,\n",
    "            \"model_a\": row_a['model'],\n",
    "            \"model_b\": row_b['model'],\n",
    "            \"num_samples_group\": num_samples_group,\n",
    "            \"summary_a_id\": row_a['id'],\n",
    "            \"summary_b_id\": row_b['id'],\n",
    "            \"summary_a_text\": row_a['summary'],\n",
    "            \"summary_b_text\": row_b['summary'],\n",
    "            \"summary_length_a\": row_a.get('summary_length', None),\n",
    "            \"summary_length_b\": row_b.get('summary_length', None)\n",
    "        }\n",
    "        processed_pair_data.append(pair_entry)\n",
    "    \n",
    "    # Print statistics for this group\n",
    "    print(f\"  Created {len(pairs_created)} pairs for this group\")\n",
    "    print(f\"  Each summary comparison count: {dict(summary_counts)}\")\n",
    "\n",
    "# Convert the processed data into a DataFrame\n",
    "processed_pair_df = pd.DataFrame(processed_pair_data)\n",
    "\n",
    "print(f\"\\nFinal statistics:\")\n",
    "print(f\"Total processed_pair_data entries: {len(processed_pair_data)}\")\n",
    "print(f\"Total question entries: {len([x for x in processed_pair_data if x.get('model') == 'question'])}\")\n",
    "print(f\"Total pair entries: {len([x for x in processed_pair_data if x.get('model_a') is not None])}\")\n",
    "print(f\"Expected pairs per group (15 summaries, min 6 comparisons each): ~{15 * 6 // 2}\")\n",
    "print(f\"Expected total pairs for all groups: ~{len(question_sample_groups) * (15 * 6 // 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimized algorithm on: Do you support the government accepting more refug..., sample_group=70\n",
      "Group size: 15\n",
      "Optimized result:\n",
      "  Created 45 pairs\n",
      "  Comparison counts: {0: 6, 1: 6, 2: 6, 3: 6, 4: 6, 5: 6, 6: 6, 7: 6, 8: 6, 9: 6, 10: 6, 11: 6, 12: 6, 13: 6, 14: 6}\n",
      "  Min comparisons: 6\n",
      "  Max comparisons: 6\n",
      "  Standard deviation: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Test the optimized algorithm on one group to see the improvement\n",
    "test_question = df['question'].iloc[0]\n",
    "test_sample_group = df['num_samples_group'].iloc[0]\n",
    "test_group = df[(df['question'] == test_question) & (df['num_samples_group'] == test_sample_group)]\n",
    "\n",
    "print(f\"Testing optimized algorithm on: {test_question[:50]}..., sample_group={test_sample_group}\")\n",
    "print(f\"Group size: {len(test_group)}\")\n",
    "\n",
    "# Run the optimized algorithm on this test group\n",
    "test_summaries = list(test_group.iterrows())\n",
    "test_pairs_created = []\n",
    "test_summary_counts = {i: 0 for i in range(len(test_summaries))}\n",
    "\n",
    "from itertools import combinations\n",
    "test_all_pairs = list(combinations(range(len(test_summaries)), 2))\n",
    "\n",
    "MIN_COMPARISONS_PER_SUMMARY = 6\n",
    "MAX_COMPARISONS_PER_SUMMARY = MIN_COMPARISONS_PER_SUMMARY + 3\n",
    "\n",
    "def balanced_pair_priority(pair_indices):\n",
    "    i, j = pair_indices\n",
    "    count_i, count_j = test_summary_counts[i], test_summary_counts[j]\n",
    "    \n",
    "    both_below_min = (count_i < MIN_COMPARISONS_PER_SUMMARY) and (count_j < MIN_COMPARISONS_PER_SUMMARY)\n",
    "    one_below_min = (count_i < MIN_COMPARISONS_PER_SUMMARY) or (count_j < MIN_COMPARISONS_PER_SUMMARY)\n",
    "    \n",
    "    max_count = max(count_i, count_j)\n",
    "    min_count = min(count_i, count_j)\n",
    "    sum_count = count_i + count_j\n",
    "    \n",
    "    if both_below_min:\n",
    "        return (0, sum_count, max_count - min_count)\n",
    "    elif one_below_min:\n",
    "        return (1, sum_count, max_count - min_count)\n",
    "    else:\n",
    "        return (2, sum_count, max_count - min_count)\n",
    "\n",
    "while any(count < MIN_COMPARISONS_PER_SUMMARY for count in test_summary_counts.values()) and test_all_pairs:\n",
    "    valid_pairs = [\n",
    "        pair for pair in test_all_pairs \n",
    "        if test_summary_counts[pair[0]] < MAX_COMPARISONS_PER_SUMMARY \n",
    "        and test_summary_counts[pair[1]] < MAX_COMPARISONS_PER_SUMMARY\n",
    "    ]\n",
    "    \n",
    "    if not valid_pairs:\n",
    "        valid_pairs = [\n",
    "            pair for pair in test_all_pairs\n",
    "            if (test_summary_counts[pair[0]] < MIN_COMPARISONS_PER_SUMMARY \n",
    "                or test_summary_counts[pair[1]] < MIN_COMPARISONS_PER_SUMMARY)\n",
    "        ]\n",
    "    \n",
    "    if not valid_pairs:\n",
    "        break\n",
    "        \n",
    "    valid_pairs.sort(key=balanced_pair_priority)\n",
    "    pair_indices = valid_pairs[0]\n",
    "    test_all_pairs.remove(pair_indices)\n",
    "    i, j = pair_indices\n",
    "    \n",
    "    test_pairs_created.append(pair_indices)\n",
    "    test_summary_counts[i] += 1\n",
    "    test_summary_counts[j] += 1\n",
    "\n",
    "print(f\"Optimized result:\")\n",
    "print(f\"  Created {len(test_pairs_created)} pairs\")\n",
    "print(f\"  Comparison counts: {dict(test_summary_counts)}\")\n",
    "print(f\"  Min comparisons: {min(test_summary_counts.values())}\")\n",
    "print(f\"  Max comparisons: {max(test_summary_counts.values())}\")\n",
    "print(f\"  Standard deviation: {np.std(list(test_summary_counts.values())):.2f}\")\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pair_df.to_csv('../data_files/processed/sum_humanstudy_pair_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating data shape: (1500, 6)\n",
      "Pair data shape: (4500, 15)\n",
      "\n",
      "Rating data columns: ['id', 'raw_id', 'question', 'text', 'model', 'summary_length']\n",
      "Pair data columns: ['id', 'raw_id', 'question', 'text', 'model', 'num_samples_group', 'summary_length', 'model_a', 'model_b', 'summary_a_id', 'summary_b_id', 'summary_a_text', 'summary_b_text', 'summary_length_a', 'summary_length_b']\n",
      "\n",
      "Rating data sample:\n",
      "                          id            raw_id  \\\n",
      "0  be44d0160fd1ec36_question  be44d0160fd1ec36   \n",
      "1   be44d0160fd1ec36_summary  be44d0160fd1ec36   \n",
      "2  c5e28aaa30501e42_question  c5e28aaa30501e42   \n",
      "\n",
      "                                            question  \\\n",
      "0  Do you support the government accepting more r...   \n",
      "1  Do you support the government accepting more r...   \n",
      "2  Do you support requiring real-name registratio...   \n",
      "\n",
      "                                                text           model  \\\n",
      "0  [Question]Do you support the government accept...  gemini-2.5-pro   \n",
      "1  <h4>Below is a summary of people's opinions on...  gemini-2.5-pro   \n",
      "2  [Question]Do you support requiring real-name r...   deepseek-chat   \n",
      "\n",
      "   summary_length  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "\n",
      "Pair data sample:\n",
      "                                                  id  \\\n",
      "0  b47684688d868a0f_bcf20dbee5035406_pair_0_question   \n",
      "1           b47684688d868a0f_bcf20dbee5035406_pair_0   \n",
      "2  c763306fb89c8d1a_ce164d741106ab5e_pair_1_question   \n",
      "\n",
      "                                     raw_id  \\\n",
      "0  b47684688d868a0f_bcf20dbee5035406_pair_0   \n",
      "1         b47684688d868a0f_bcf20dbee5035406   \n",
      "2  c763306fb89c8d1a_ce164d741106ab5e_pair_1   \n",
      "\n",
      "                                            question  \\\n",
      "0  Do you support requiring real-name registratio...   \n",
      "1  Do you support requiring real-name registratio...   \n",
      "2  Do you support requiring real-name registratio...   \n",
      "\n",
      "                                                text     model  \\\n",
      "0  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "1  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "2  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "\n",
      "   num_samples_group  summary_length         model_a    model_b  \\\n",
      "0                 10             NaN             NaN        NaN   \n",
      "1                 10             NaN  gemini-2.5-pro  qwen3-32b   \n",
      "2                 10             NaN             NaN        NaN   \n",
      "\n",
      "       summary_a_id      summary_b_id  \\\n",
      "0               NaN               NaN   \n",
      "1  b47684688d868a0f  bcf20dbee5035406   \n",
      "2               NaN               NaN   \n",
      "\n",
      "                                      summary_a_text  \\\n",
      "0                                                NaN   \n",
      "1  Here is a summary of the comments provided:\\n\\...   \n",
      "2                                                NaN   \n",
      "\n",
      "                                      summary_b_text  summary_length_a  \\\n",
      "0                                                NaN               NaN   \n",
      "1  **Summary of Comments:**\\n\\nThe comments refle...               NaN   \n",
      "2                                                NaN               NaN   \n",
      "\n",
      "   summary_length_b  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load both datasets for natural join\n",
    "rating_df = pd.read_csv('../data_files/processed/sum_humanstudy_rating_full.csv')\n",
    "pair_df = pd.read_csv('../data_files/processed/sum_humanstudy_pair_full.csv')\n",
    "\n",
    "print(f\"Rating data shape: {rating_df.shape}\")\n",
    "print(f\"Pair data shape: {pair_df.shape}\")\n",
    "\n",
    "# Check the structure\n",
    "print(\"\\nRating data columns:\", rating_df.columns.tolist())\n",
    "print(\"Pair data columns:\", pair_df.columns.tolist())\n",
    "\n",
    "print(\"\\nRating data sample:\")\n",
    "print(rating_df.head(3))\n",
    "print(\"\\nPair data sample:\")\n",
    "print(pair_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding data structure...\n",
      "Rating data: 1500 total rows\n",
      "Pair data: 4500 total rows\n",
      "Debugging pair data structure...\n",
      "First few rows of pair_df:\n",
      "                                                  id  \\\n",
      "0  b47684688d868a0f_bcf20dbee5035406_pair_0_question   \n",
      "1           b47684688d868a0f_bcf20dbee5035406_pair_0   \n",
      "2  c763306fb89c8d1a_ce164d741106ab5e_pair_1_question   \n",
      "3           c763306fb89c8d1a_ce164d741106ab5e_pair_1   \n",
      "4  ad3135722c23a68f_ec6a5ffe40b150f0_pair_2_question   \n",
      "5           ad3135722c23a68f_ec6a5ffe40b150f0_pair_2   \n",
      "6  7cb5806a4aa6f3ff_38a9bde51b2e82b9_pair_3_question   \n",
      "7           7cb5806a4aa6f3ff_38a9bde51b2e82b9_pair_3   \n",
      "8  dcb26be08b758bb5_97800d729fb0bca1_pair_4_question   \n",
      "9           dcb26be08b758bb5_97800d729fb0bca1_pair_4   \n",
      "\n",
      "                                     raw_id  \\\n",
      "0  b47684688d868a0f_bcf20dbee5035406_pair_0   \n",
      "1         b47684688d868a0f_bcf20dbee5035406   \n",
      "2  c763306fb89c8d1a_ce164d741106ab5e_pair_1   \n",
      "3         c763306fb89c8d1a_ce164d741106ab5e   \n",
      "4  ad3135722c23a68f_ec6a5ffe40b150f0_pair_2   \n",
      "5         ad3135722c23a68f_ec6a5ffe40b150f0   \n",
      "6  7cb5806a4aa6f3ff_38a9bde51b2e82b9_pair_3   \n",
      "7         7cb5806a4aa6f3ff_38a9bde51b2e82b9   \n",
      "8  dcb26be08b758bb5_97800d729fb0bca1_pair_4   \n",
      "9         dcb26be08b758bb5_97800d729fb0bca1   \n",
      "\n",
      "                                            question  \\\n",
      "0  Do you support requiring real-name registratio...   \n",
      "1  Do you support requiring real-name registratio...   \n",
      "2  Do you support requiring real-name registratio...   \n",
      "3  Do you support requiring real-name registratio...   \n",
      "4  Do you support requiring real-name registratio...   \n",
      "5  Do you support requiring real-name registratio...   \n",
      "6  Do you support requiring real-name registratio...   \n",
      "7  Do you support requiring real-name registratio...   \n",
      "8  Do you support requiring real-name registratio...   \n",
      "9  Do you support requiring real-name registratio...   \n",
      "\n",
      "                                                text     model  \\\n",
      "0  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "1  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "2  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "3  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "4  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "5  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "6  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "7  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "8  <h3>[Question]</h3><h4>Do you support requirin...  question   \n",
      "9  <h4>Two summaries of opinions are shown below....       NaN   \n",
      "\n",
      "   num_samples_group  summary_length         model_a  \\\n",
      "0                 10             NaN             NaN   \n",
      "1                 10             NaN  gemini-2.5-pro   \n",
      "2                 10             NaN             NaN   \n",
      "3                 10             NaN           gpt-5   \n",
      "4                 10             NaN             NaN   \n",
      "5                 10             NaN  gemini-2.5-pro   \n",
      "6                 10             NaN             NaN   \n",
      "7                 10             NaN   deepseek-chat   \n",
      "8                 10             NaN             NaN   \n",
      "9                 10             NaN   deepseek-chat   \n",
      "\n",
      "                          model_b      summary_a_id      summary_b_id  \\\n",
      "0                             NaN               NaN               NaN   \n",
      "1                       qwen3-32b  b47684688d868a0f  bcf20dbee5035406   \n",
      "2                             NaN               NaN               NaN   \n",
      "3                       qwen3-32b  c763306fb89c8d1a  ce164d741106ab5e   \n",
      "4                             NaN               NaN               NaN   \n",
      "5  web-rev-claude-opus-4-20250514  ad3135722c23a68f  ec6a5ffe40b150f0   \n",
      "6                             NaN               NaN               NaN   \n",
      "7                           gpt-5  7cb5806a4aa6f3ff  38a9bde51b2e82b9   \n",
      "8                             NaN               NaN               NaN   \n",
      "9                   deepseek-chat  dcb26be08b758bb5  97800d729fb0bca1   \n",
      "\n",
      "                                      summary_a_text  \\\n",
      "0                                                NaN   \n",
      "1  Here is a summary of the comments provided:\\n\\...   \n",
      "2                                                NaN   \n",
      "3  Overall summary:\\n- Sentiment: Opposition domi...   \n",
      "4                                                NaN   \n",
      "5  Here is a summary of the comments provided:\\n\\...   \n",
      "6                                                NaN   \n",
      "7  A majority of voices oppose mandatory real ide...   \n",
      "8                                                NaN   \n",
      "9  Overall, comments reveal a clear division betw...   \n",
      "\n",
      "                                      summary_b_text  summary_length_a  \\\n",
      "0                                                NaN               NaN   \n",
      "1  **Summary of Comments:**\\n\\nThe comments refle...               NaN   \n",
      "2                                                NaN               NaN   \n",
      "3  **Summary of Comments:**\\n\\nThe comments refle...               NaN   \n",
      "4                                                NaN               NaN   \n",
      "5  ## Summary of Comments on Real Identity Requir...               NaN   \n",
      "6                                                NaN               NaN   \n",
      "7  Overall summary of views:\\n- Overall sentiment...               NaN   \n",
      "8                                                NaN               NaN   \n",
      "9  Overall, the comments reveal a divided perspec...               NaN   \n",
      "\n",
      "   summary_length_b  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "6               NaN  \n",
      "7               NaN  \n",
      "8               NaN  \n",
      "9               NaN  \n",
      "\n",
      "Checking model column values:\n",
      "model\n",
      "question    2250\n",
      "Name: count, dtype: int64\n",
      "Row 0: model='question', raw_id='b47684688d868a0f_bcf20dbee5035406_pair_0'\n",
      "Row 1: model='nan', raw_id='b47684688d868a0f_bcf20dbee5035406'\n",
      "  Comparing: 'b47684688d868a0f_bcf20dbee5035406' == 'b47684688d868a0f_bcf20dbee5035406'\n",
      "  -> Added pair comparison\n",
      "Row 2: model='question', raw_id='c763306fb89c8d1a_ce164d741106ab5e_pair_1'\n",
      "Row 3: model='nan', raw_id='c763306fb89c8d1a_ce164d741106ab5e'\n",
      "  Comparing: 'c763306fb89c8d1a_ce164d741106ab5e' == 'c763306fb89c8d1a_ce164d741106ab5e'\n",
      "  -> Added pair comparison\n",
      "Row 4: model='question', raw_id='ad3135722c23a68f_ec6a5ffe40b150f0_pair_2'\n",
      "Row 5: model='nan', raw_id='ad3135722c23a68f_ec6a5ffe40b150f0'\n",
      "  Comparing: 'ad3135722c23a68f_ec6a5ffe40b150f0' == 'ad3135722c23a68f_ec6a5ffe40b150f0'\n",
      "  -> Added pair comparison\n",
      "Row 6: model='question', raw_id='7cb5806a4aa6f3ff_38a9bde51b2e82b9_pair_3'\n",
      "Row 7: model='nan', raw_id='7cb5806a4aa6f3ff_38a9bde51b2e82b9'\n",
      "  Comparing: '7cb5806a4aa6f3ff_38a9bde51b2e82b9' == '7cb5806a4aa6f3ff_38a9bde51b2e82b9'\n",
      "  -> Added pair comparison\n",
      "Row 8: model='question', raw_id='dcb26be08b758bb5_97800d729fb0bca1_pair_4'\n",
      "Row 9: model='nan', raw_id='dcb26be08b758bb5_97800d729fb0bca1'\n",
      "  Comparing: 'dcb26be08b758bb5_97800d729fb0bca1' == 'dcb26be08b758bb5_97800d729fb0bca1'\n",
      "  -> Added pair comparison\n",
      "Row 10: model='question', raw_id='a368f52fd450713b_b2c3275416c437cc_pair_5'\n",
      "Row 11: model='nan', raw_id='a368f52fd450713b_b2c3275416c437cc'\n",
      "  Comparing: 'a368f52fd450713b_b2c3275416c437cc' == 'a368f52fd450713b_b2c3275416c437cc'\n",
      "  -> Added pair comparison\n",
      "Row 12: model='question', raw_id='f8fc8109a8cf5255_e3a40367cdc62bc1_pair_6'\n",
      "Row 13: model='nan', raw_id='f8fc8109a8cf5255_e3a40367cdc62bc1'\n",
      "  Comparing: 'f8fc8109a8cf5255_e3a40367cdc62bc1' == 'f8fc8109a8cf5255_e3a40367cdc62bc1'\n",
      "  -> Added pair comparison\n",
      "Row 14: model='question', raw_id='b47684688d868a0f_8172525bd422435b_pair_7'\n",
      "Row 15: model='nan', raw_id='b47684688d868a0f_8172525bd422435b'\n",
      "  Comparing: 'b47684688d868a0f_8172525bd422435b' == 'b47684688d868a0f_8172525bd422435b'\n",
      "  -> Added pair comparison\n",
      "Row 16: model='question', raw_id='bcf20dbee5035406_c763306fb89c8d1a_pair_8'\n",
      "Row 17: model='nan', raw_id='bcf20dbee5035406_c763306fb89c8d1a'\n",
      "  Comparing: 'bcf20dbee5035406_c763306fb89c8d1a' == 'bcf20dbee5035406_c763306fb89c8d1a'\n",
      "  -> Added pair comparison\n",
      "Row 18: model='question', raw_id='ce164d741106ab5e_ad3135722c23a68f_pair_9'\n",
      "Row 19: model='nan', raw_id='ce164d741106ab5e_ad3135722c23a68f'\n",
      "  Comparing: 'ce164d741106ab5e_ad3135722c23a68f' == 'ce164d741106ab5e_ad3135722c23a68f'\n",
      "  -> Added pair comparison\n",
      "Row 200: model='question', raw_id='0a208ca9e7fdf00f_f0835ba6b89f9dc2_pair_10'\n",
      "Row 201: model='nan', raw_id='0a208ca9e7fdf00f_f0835ba6b89f9dc2'\n",
      "  Comparing: '0a208ca9e7fdf00f_f0835ba6b89f9dc2' == '0a208ca9e7fdf00f_f0835ba6b89f9dc2'\n",
      "  -> Added pair comparison\n",
      "Row 400: model='question', raw_id='356c7e4bcdaee074_6cb59535e826d69f_pair_20'\n",
      "Row 401: model='nan', raw_id='356c7e4bcdaee074_6cb59535e826d69f'\n",
      "  Comparing: '356c7e4bcdaee074_6cb59535e826d69f' == '356c7e4bcdaee074_6cb59535e826d69f'\n",
      "  -> Added pair comparison\n",
      "Row 600: model='question', raw_id='7d9b8802daf25b29_6af71510e9c733db_pair_30'\n",
      "Row 601: model='nan', raw_id='7d9b8802daf25b29_6af71510e9c733db'\n",
      "  Comparing: '7d9b8802daf25b29_6af71510e9c733db' == '7d9b8802daf25b29_6af71510e9c733db'\n",
      "  -> Added pair comparison\n",
      "Row 800: model='question', raw_id='8a675bf3fe4d5eba_a68ee28118eeddbd_pair_40'\n",
      "Row 801: model='nan', raw_id='8a675bf3fe4d5eba_a68ee28118eeddbd'\n",
      "  Comparing: '8a675bf3fe4d5eba_a68ee28118eeddbd' == '8a675bf3fe4d5eba_a68ee28118eeddbd'\n",
      "  -> Added pair comparison\n",
      "Row 1000: model='question', raw_id='0502a808a87bbe73_099291b90e7d23ee_pair_5'\n",
      "Row 1001: model='nan', raw_id='0502a808a87bbe73_099291b90e7d23ee'\n",
      "  Comparing: '0502a808a87bbe73_099291b90e7d23ee' == '0502a808a87bbe73_099291b90e7d23ee'\n",
      "  -> Added pair comparison\n",
      "Row 1200: model='question', raw_id='6dbb3605eb32d14a_f9d2d40d0af88c9b_pair_15'\n",
      "Row 1201: model='nan', raw_id='6dbb3605eb32d14a_f9d2d40d0af88c9b'\n",
      "  Comparing: '6dbb3605eb32d14a_f9d2d40d0af88c9b' == '6dbb3605eb32d14a_f9d2d40d0af88c9b'\n",
      "  -> Added pair comparison\n",
      "Row 1400: model='question', raw_id='3590f3df41e6b6d0_ae10460ea5c8b5e6_pair_25'\n",
      "Row 1401: model='nan', raw_id='3590f3df41e6b6d0_ae10460ea5c8b5e6'\n",
      "  Comparing: '3590f3df41e6b6d0_ae10460ea5c8b5e6' == '3590f3df41e6b6d0_ae10460ea5c8b5e6'\n",
      "  -> Added pair comparison\n",
      "Row 1600: model='question', raw_id='eeb5abd885166f2b_121dfffc9722d674_pair_35'\n",
      "Row 1601: model='nan', raw_id='eeb5abd885166f2b_121dfffc9722d674'\n",
      "  Comparing: 'eeb5abd885166f2b_121dfffc9722d674' == 'eeb5abd885166f2b_121dfffc9722d674'\n",
      "  -> Added pair comparison\n",
      "Row 1800: model='question', raw_id='178f8f906f7c0491_5b4fa07a001f15aa_pair_0'\n",
      "Row 1801: model='nan', raw_id='178f8f906f7c0491_5b4fa07a001f15aa'\n",
      "  Comparing: '178f8f906f7c0491_5b4fa07a001f15aa' == '178f8f906f7c0491_5b4fa07a001f15aa'\n",
      "  -> Added pair comparison\n",
      "Row 2000: model='question', raw_id='ae4bff77ac291f5b_61dd546c78c8eca6_pair_10'\n",
      "Row 2001: model='nan', raw_id='ae4bff77ac291f5b_61dd546c78c8eca6'\n",
      "  Comparing: 'ae4bff77ac291f5b_61dd546c78c8eca6' == 'ae4bff77ac291f5b_61dd546c78c8eca6'\n",
      "  -> Added pair comparison\n",
      "Row 2200: model='question', raw_id='5b26f4c1115d5856_83a2ebd6017b4ca9_pair_20'\n",
      "Row 2201: model='nan', raw_id='5b26f4c1115d5856_83a2ebd6017b4ca9'\n",
      "  Comparing: '5b26f4c1115d5856_83a2ebd6017b4ca9' == '5b26f4c1115d5856_83a2ebd6017b4ca9'\n",
      "  -> Added pair comparison\n",
      "Row 2400: model='question', raw_id='43244ce31b056126_539d201d98aeabd5_pair_30'\n",
      "Row 2401: model='nan', raw_id='43244ce31b056126_539d201d98aeabd5'\n",
      "  Comparing: '43244ce31b056126_539d201d98aeabd5' == '43244ce31b056126_539d201d98aeabd5'\n",
      "  -> Added pair comparison\n",
      "Row 2600: model='question', raw_id='c9586deef4c4078a_793bc143b8b2f483_pair_40'\n",
      "Row 2601: model='nan', raw_id='c9586deef4c4078a_793bc143b8b2f483'\n",
      "  Comparing: 'c9586deef4c4078a_793bc143b8b2f483' == 'c9586deef4c4078a_793bc143b8b2f483'\n",
      "  -> Added pair comparison\n",
      "Row 2800: model='question', raw_id='25db8c4f7669aef7_c481d7d172938078_pair_5'\n",
      "Row 2801: model='nan', raw_id='25db8c4f7669aef7_c481d7d172938078'\n",
      "  Comparing: '25db8c4f7669aef7_c481d7d172938078' == '25db8c4f7669aef7_c481d7d172938078'\n",
      "  -> Added pair comparison\n",
      "Row 3000: model='question', raw_id='1bfe447ea77652dd_d8ff52d6609ab562_pair_15'\n",
      "Row 3001: model='nan', raw_id='1bfe447ea77652dd_d8ff52d6609ab562'\n",
      "  Comparing: '1bfe447ea77652dd_d8ff52d6609ab562' == '1bfe447ea77652dd_d8ff52d6609ab562'\n",
      "  -> Added pair comparison\n",
      "Row 3200: model='question', raw_id='a0c22961a4efe7b4_9fcc2a582eaf948f_pair_25'\n",
      "Row 3201: model='nan', raw_id='a0c22961a4efe7b4_9fcc2a582eaf948f'\n",
      "  Comparing: 'a0c22961a4efe7b4_9fcc2a582eaf948f' == 'a0c22961a4efe7b4_9fcc2a582eaf948f'\n",
      "  -> Added pair comparison\n",
      "Row 3400: model='question', raw_id='58236966af35e38e_a04033b906a6a763_pair_35'\n",
      "Row 3401: model='nan', raw_id='58236966af35e38e_a04033b906a6a763'\n",
      "  Comparing: '58236966af35e38e_a04033b906a6a763' == '58236966af35e38e_a04033b906a6a763'\n",
      "  -> Added pair comparison\n",
      "Row 3600: model='question', raw_id='22525519f9b047aa_51d5a74569d5a9d4_pair_0'\n",
      "Row 3601: model='nan', raw_id='22525519f9b047aa_51d5a74569d5a9d4'\n",
      "  Comparing: '22525519f9b047aa_51d5a74569d5a9d4' == '22525519f9b047aa_51d5a74569d5a9d4'\n",
      "  -> Added pair comparison\n",
      "Row 3800: model='question', raw_id='7553cea3d175fe31_1375142d86a25520_pair_10'\n",
      "Row 3801: model='nan', raw_id='7553cea3d175fe31_1375142d86a25520'\n",
      "  Comparing: '7553cea3d175fe31_1375142d86a25520' == '7553cea3d175fe31_1375142d86a25520'\n",
      "  -> Added pair comparison\n",
      "Row 4000: model='question', raw_id='12cb10de2d4b371c_d0110ee121de44ee_pair_20'\n",
      "Row 4001: model='nan', raw_id='12cb10de2d4b371c_d0110ee121de44ee'\n",
      "  Comparing: '12cb10de2d4b371c_d0110ee121de44ee' == '12cb10de2d4b371c_d0110ee121de44ee'\n",
      "  -> Added pair comparison\n",
      "Row 4200: model='question', raw_id='a1c988af2cb024f9_8c3485101bf459d3_pair_30'\n",
      "Row 4201: model='nan', raw_id='a1c988af2cb024f9_8c3485101bf459d3'\n",
      "  Comparing: 'a1c988af2cb024f9_8c3485101bf459d3' == 'a1c988af2cb024f9_8c3485101bf459d3'\n",
      "  -> Added pair comparison\n",
      "Row 4400: model='question', raw_id='47e3b5474e66c1f6_43d7562af410269f_pair_40'\n",
      "Row 4401: model='nan', raw_id='47e3b5474e66c1f6_43d7562af410269f'\n",
      "  Comparing: '47e3b5474e66c1f6_43d7562af410269f' == '47e3b5474e66c1f6_43d7562af410269f'\n",
      "  -> Added pair comparison\n",
      "Extracted 750 rating pairs\n",
      "Extracted 2250 comparison pairs\n"
     ]
    }
   ],
   "source": [
    "# Correct understanding: Both datasets have pairs of rows\n",
    "# Rating: question + rating summary (2 rows per pair)  \n",
    "# Pair: question + comparison (2 rows per pair)\n",
    "# Goal: Create triplets by natural join on raw_id\n",
    "\n",
    "print(\"Understanding data structure...\")\n",
    "print(f\"Rating data: {len(rating_df)} total rows\")\n",
    "print(f\"Pair data: {len(pair_df)} total rows\")\n",
    "\n",
    "# Extract rating pairs (question + summary)\n",
    "rating_pairs = []\n",
    "for i in range(0, len(rating_df), 2):\n",
    "    if i + 1 < len(rating_df):\n",
    "        question_row = rating_df.iloc[i]\n",
    "        summary_row = rating_df.iloc[i + 1]\n",
    "        \n",
    "        # Verify this is a proper pair\n",
    "        if (question_row['raw_id'] == summary_row['raw_id'] and \n",
    "            '_question' in question_row['id'] and \n",
    "            '_summary' in summary_row['id']):\n",
    "            rating_pairs.append({\n",
    "                'raw_id': question_row['raw_id'],\n",
    "                'question': question_row['question'],\n",
    "                'question_text': question_row['text'],\n",
    "                'summary_text': summary_row['text'],\n",
    "                'model': question_row['model'],\n",
    "                'summary_length': question_row.get('summary_length')\n",
    "            })\n",
    "\n",
    "# Debug: Check the pair data structure first\n",
    "print(\"Debugging pair data structure...\")\n",
    "print(f\"First few rows of pair_df:\")\n",
    "print(pair_df.head(10))\n",
    "print(f\"\\nChecking model column values:\")\n",
    "print(pair_df['model'].value_counts())\n",
    "\n",
    "# Extract pair comparisons (question + comparison)  \n",
    "pair_comparisons = []\n",
    "for i in range(0, len(pair_df), 2):\n",
    "    if i + 1 < len(pair_df):\n",
    "        question_row = pair_df.iloc[i]\n",
    "        comparison_row = pair_df.iloc[i + 1]\n",
    "        \n",
    "        # Show progress for debugging (only first few and every 100th)\n",
    "        if i < 20 or i % 200 == 0:\n",
    "            print(f\"Row {i}: model='{question_row['model']}', raw_id='{question_row['raw_id']}'\")\n",
    "            print(f\"Row {i+1}: model='{comparison_row['model']}', raw_id='{comparison_row['raw_id']}'\")\n",
    "        \n",
    "        # Verify this is a proper pair\n",
    "        # Question row has '_pair_X' suffix, comparison row doesn't\n",
    "        question_base_id = question_row['raw_id'].rsplit('_pair_', 1)[0] if '_pair_' in question_row['raw_id'] else question_row['raw_id']\n",
    "        comparison_base_id = comparison_row['raw_id']\n",
    "        \n",
    "        if i < 20 or i % 200 == 0:\n",
    "            print(f\"  Comparing: '{question_base_id}' == '{comparison_base_id}'\")\n",
    "        \n",
    "        if (question_base_id == comparison_base_id and\n",
    "            question_row['model'] == 'question'):\n",
    "            pair_comparisons.append({\n",
    "                'raw_id': comparison_row['raw_id'], \n",
    "                'question': question_row['question'],\n",
    "                'question_text': question_row['text'],\n",
    "                'comparison_text': comparison_row['text'],\n",
    "                'model_a': comparison_row.get('model_a'),\n",
    "                'model_b': comparison_row.get('model_b'),\n",
    "                'summary_a_id': comparison_row.get('summary_a_id'),\n",
    "                'summary_b_id': comparison_row.get('summary_b_id'),\n",
    "                'summary_a_text': comparison_row.get('summary_a_text'),\n",
    "                'summary_b_text': comparison_row.get('summary_b_text')\n",
    "            })\n",
    "            if i < 20 or i % 200 == 0:\n",
    "                print(f\"  -> Added pair comparison\")\n",
    "        else:\n",
    "            if i < 20 or i % 200 == 0:\n",
    "                print(f\"  -> Skipped: base_id_match={question_base_id == comparison_base_id}, model_check={question_row['model'] == 'question'}\")\n",
    "\n",
    "print(f\"Extracted {len(rating_pairs)} rating pairs\")\n",
    "print(f\"Extracted {len(pair_comparisons)} comparison pairs\")\n",
    "\n",
    "# Convert to DataFrames for easier joining\n",
    "rating_pairs_df = pd.DataFrame(rating_pairs)\n",
    "pair_comparisons_df = pd.DataFrame(pair_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating triplets by matching summary_a_id...\n",
      "Total pair comparisons: 2250\n",
      "Rating pairs sample:\n",
      "             raw_id                                           question  \\\n",
      "0  be44d0160fd1ec36  Do you support the government accepting more r...   \n",
      "1  c5e28aaa30501e42  Do you support requiring real-name registratio...   \n",
      "2  ad06843babdcceca  Do you support requiring real-name registratio...   \n",
      "\n",
      "                                       question_text  \\\n",
      "0  [Question]Do you support the government accept...   \n",
      "1  [Question]Do you support requiring real-name r...   \n",
      "2  [Question]Do you support requiring real-name r...   \n",
      "\n",
      "                                        summary_text  \\\n",
      "0  <h4>Below is a summary of people's opinions on...   \n",
      "1  <h4>Below is a summary of people's opinions on...   \n",
      "2  <h4>Below is a summary of people's opinions on...   \n",
      "\n",
      "                            model  summary_length  \n",
      "0                  gemini-2.5-pro             NaN  \n",
      "1                   deepseek-chat             NaN  \n",
      "2  web-rev-claude-opus-4-20250514             NaN  \n",
      "Rating pairs columns: ['raw_id', 'question', 'question_text', 'summary_text', 'model', 'summary_length']\n",
      "Created lookup for 750 rating summaries\n",
      "Sample rating raw_ids: ['be44d0160fd1ec36', 'c5e28aaa30501e42', 'ad06843babdcceca', 'e38ed9ce8b9e3220', '5eb7a59774dbb009']\n",
      "Sample pair summary_a_ids: ['b47684688d868a0f', 'c763306fb89c8d1a', 'ad3135722c23a68f', '7cb5806a4aa6f3ff', 'dcb26be08b758bb5']\n",
      "Matched 2250 pair comparisons with ratings\n",
      "Unmatched 0 pair comparisons\n",
      "Total triplets created: 2250\n",
      "Total rows: 6750\n",
      "Rating usage stats: min=1, max=6, avg=3.2\n"
     ]
    }
   ],
   "source": [
    "# Match by summary_a_id: For each pair comparison, find rating with matching ID\n",
    "print(\"Creating triplets by matching summary_a_id...\")\n",
    "print(f\"Total pair comparisons: {len(pair_comparisons_df)}\")\n",
    "\n",
    "# Debug: Check rating_pairs_df structure first\n",
    "print(f\"Rating pairs sample:\")\n",
    "print(rating_pairs_df.head(3))\n",
    "print(f\"Rating pairs columns: {rating_pairs_df.columns.tolist()}\")\n",
    "\n",
    "# Create a lookup dictionary for faster matching: rating_raw_id -> rating_pair\n",
    "ratings_by_id = {}\n",
    "for _, rating_pair in rating_pairs_df.iterrows():\n",
    "    # Use the raw_id from rating data as the key\n",
    "    raw_id = rating_pair['raw_id']\n",
    "    ratings_by_id[raw_id] = rating_pair\n",
    "\n",
    "print(f\"Created lookup for {len(ratings_by_id)} rating summaries\")\n",
    "print(f\"Sample rating raw_ids: {list(ratings_by_id.keys())[:5]}\")\n",
    "\n",
    "# Debug: Check pair summary_a_id format\n",
    "print(f\"Sample pair summary_a_ids: {pair_comparisons_df['summary_a_id'].head(5).tolist()}\")\n",
    "\n",
    "# For each pair comparison, match by summary_a_id\n",
    "joined_data = []\n",
    "matched_count = 0\n",
    "unmatched_count = 0\n",
    "rating_usage_count = {}\n",
    "\n",
    "for idx, comparison_pair in pair_comparisons_df.iterrows():\n",
    "    summary_a_id = comparison_pair['summary_a_id']\n",
    "    pair_raw_id = comparison_pair['raw_id']\n",
    "    question = comparison_pair['question']\n",
    "    \n",
    "    # Find rating pair with matching summary_a_id\n",
    "    if summary_a_id in ratings_by_id:\n",
    "        matched_count += 1\n",
    "        rating_pair = ratings_by_id[summary_a_id]\n",
    "        \n",
    "        # Track usage\n",
    "        rating_usage_count[summary_a_id] = rating_usage_count.get(summary_a_id, 0) + 1\n",
    "        \n",
    "        # Create the triplet: question + rating + comparison\n",
    "        clean_question = question.replace(\" Please answer briefly in 2–3 sentences.\", \"\").replace(\"Please answer briefly in 1–2 sentences.\", \"\")\n",
    "        \n",
    "        # Use pair's raw_id as the triplet identifier\n",
    "        triplet_id = f\"triplet_{idx}\"\n",
    "        \n",
    "        # Row 1: Question (with proper HTML formatting, preserve all columns)\n",
    "        question_row = {\n",
    "            'id': f\"{triplet_id}_question\",\n",
    "            'raw_id': pair_raw_id,\n",
    "            'question': question,\n",
    "            'text': f'<h3>[Question]</h3><h4>{clean_question}</h4>',\n",
    "            'type': 'question',\n",
    "            'model': 'question',\n",
    "            'num_samples_group': comparison_pair.get('num_samples_group'),\n",
    "            'summary_length': None,\n",
    "            'model_a': None,\n",
    "            'model_b': None,\n",
    "            'summary_a_id': None,\n",
    "            'summary_b_id': None,\n",
    "            'summary_a_text': None,\n",
    "            'summary_b_text': None,\n",
    "            'summary_length_a': None,\n",
    "            'summary_length_b': None\n",
    "        }\n",
    "        joined_data.append(question_row)\n",
    "        \n",
    "        # Row 2: Rating (from rating data, matched by summary_a_id, preserve all columns)\n",
    "        rating_row = {\n",
    "            'id': f\"{triplet_id}_rating\",\n",
    "            'raw_id': pair_raw_id,\n",
    "            'question': question,\n",
    "            'text': rating_pair['summary_text'],\n",
    "            'type': 'rating',\n",
    "            'model': rating_pair['model'],\n",
    "            'num_samples_group': comparison_pair.get('num_samples_group'),\n",
    "            'summary_length': rating_pair.get('summary_length'),\n",
    "            'model_a': None,\n",
    "            'model_b': None,\n",
    "            'summary_a_id': None,\n",
    "            'summary_b_id': None,\n",
    "            'summary_a_text': None,\n",
    "            'summary_b_text': None,\n",
    "            'summary_length_a': None,\n",
    "            'summary_length_b': None\n",
    "        }\n",
    "        joined_data.append(rating_row)\n",
    "        \n",
    "        # Row 3: Comparison (from pair data, preserve all columns)\n",
    "        comparison_row = {\n",
    "            'id': f\"{triplet_id}_comparison\",\n",
    "            'raw_id': pair_raw_id,\n",
    "            'question': question,\n",
    "            'text': comparison_pair['comparison_text'],\n",
    "            'type': 'comparison',\n",
    "            'model': 'comparison',\n",
    "            'num_samples_group': comparison_pair.get('num_samples_group'),\n",
    "            'summary_length': None,\n",
    "            'model_a': comparison_pair.get('model_a'),\n",
    "            'model_b': comparison_pair.get('model_b'),\n",
    "            'summary_a_id': comparison_pair.get('summary_a_id'),\n",
    "            'summary_b_id': comparison_pair.get('summary_b_id'),\n",
    "            'summary_a_text': comparison_pair.get('summary_a_text'),\n",
    "            'summary_b_text': comparison_pair.get('summary_b_text'),\n",
    "            'summary_length_a': comparison_pair.get('summary_length_a'),\n",
    "            'summary_length_b': comparison_pair.get('summary_length_b')\n",
    "        }\n",
    "        joined_data.append(comparison_row)\n",
    "    else:\n",
    "        unmatched_count += 1\n",
    "        if idx < 5:  # Show first few unmatched for debugging\n",
    "            print(f\"No match found for summary_a_id: {summary_a_id}\")\n",
    "\n",
    "print(f\"Matched {matched_count} pair comparisons with ratings\")\n",
    "print(f\"Unmatched {unmatched_count} pair comparisons\")\n",
    "print(f\"Total triplets created: {len(joined_data) // 3}\")\n",
    "print(f\"Total rows: {len(joined_data)}\")\n",
    "\n",
    "# Check rating usage distribution\n",
    "if rating_usage_count:\n",
    "    usage_values = list(rating_usage_count.values())\n",
    "    print(f\"Rating usage stats: min={min(usage_values)}, max={max(usage_values)}, avg={sum(usage_values)/len(usage_values):.1f}\")\n",
    "\n",
    "# Create final DataFrame\n",
    "triplet_df = pd.DataFrame(joined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debugging triplet_df structure:\n",
      "triplet_df shape: (6750, 16)\n",
      "triplet_df columns: ['id', 'raw_id', 'question', 'text', 'type', 'model', 'num_samples_group', 'summary_length', 'model_a', 'model_b', 'summary_a_id', 'summary_b_id', 'summary_a_text', 'summary_b_text', 'summary_length_a', 'summary_length_b']\n",
      "First few rows:\n",
      "                     id                             raw_id  \\\n",
      "0    triplet_0_question  b47684688d868a0f_bcf20dbee5035406   \n",
      "1      triplet_0_rating  b47684688d868a0f_bcf20dbee5035406   \n",
      "2  triplet_0_comparison  b47684688d868a0f_bcf20dbee5035406   \n",
      "3    triplet_1_question  c763306fb89c8d1a_ce164d741106ab5e   \n",
      "4      triplet_1_rating  c763306fb89c8d1a_ce164d741106ab5e   \n",
      "\n",
      "                                            question  \\\n",
      "0  Do you support requiring real-name registratio...   \n",
      "1  Do you support requiring real-name registratio...   \n",
      "2  Do you support requiring real-name registratio...   \n",
      "3  Do you support requiring real-name registratio...   \n",
      "4  Do you support requiring real-name registratio...   \n",
      "\n",
      "                                                text        type  \\\n",
      "0  <h3>[Question]</h3><h4>Do you support requirin...    question   \n",
      "1  <h4>Below is a summary of people's opinions on...      rating   \n",
      "2  <h4>Two summaries of opinions are shown below....  comparison   \n",
      "3  <h3>[Question]</h3><h4>Do you support requirin...    question   \n",
      "4  <h4>Below is a summary of people's opinions on...      rating   \n",
      "\n",
      "            model num_samples_group  summary_length         model_a  \\\n",
      "0        question              None             NaN            None   \n",
      "1  gemini-2.5-pro              None             NaN            None   \n",
      "2      comparison              None             NaN  gemini-2.5-pro   \n",
      "3        question              None             NaN            None   \n",
      "4           gpt-5              None             NaN            None   \n",
      "\n",
      "     model_b      summary_a_id      summary_b_id  \\\n",
      "0       None              None              None   \n",
      "1       None              None              None   \n",
      "2  qwen3-32b  b47684688d868a0f  bcf20dbee5035406   \n",
      "3       None              None              None   \n",
      "4       None              None              None   \n",
      "\n",
      "                                      summary_a_text  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2  Here is a summary of the comments provided:\\n\\...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                      summary_b_text summary_length_a  \\\n",
      "0                                               None             None   \n",
      "1                                               None             None   \n",
      "2  **Summary of Comments:**\\n\\nThe comments refle...             None   \n",
      "3                                               None             None   \n",
      "4                                               None             None   \n",
      "\n",
      "  summary_length_b  \n",
      "0             None  \n",
      "1             None  \n",
      "2             None  \n",
      "3             None  \n",
      "4             None  \n",
      "\n",
      "Verifying triplet structure:\n",
      "Question entries: 2250\n",
      "Rating entries: 2250\n",
      "Comparison entries: 2250\n",
      "\n",
      "Sample triplet structure:\n",
      "\n",
      "Triplet 1:\n",
      "  Question: <h3>[Question]</h3><h4>Do you support requiring real-name registration on social media platforms, where users must register and post under their real identity?</h4>\n",
      "  Rating: <h4>Below is a summary of people's opinions on the issue.</h4><hr><p>Here is a summary of the commen...\n",
      "  Comparison: <h4>Two summaries of opinions are shown below. Read carefully and answer according to your prior opi...\n",
      "\n",
      "Triplet 2:\n",
      "  Question: <h3>[Question]</h3><h4>Do you support requiring real-name registration on social media platforms, where users must register and post under their real identity?</h4>\n",
      "  Rating: <h4>Below is a summary of people's opinions on the issue.</h4><hr><p>Overall summary:\n",
      "- Sentiment: O...\n",
      "  Comparison: <h4>Two summaries of opinions are shown below. Read carefully and answer according to your prior opi...\n",
      "\n",
      "Triplet 3:\n",
      "  Question: <h3>[Question]</h3><h4>Do you support requiring real-name registration on social media platforms, where users must register and post under their real identity?</h4>\n",
      "  Rating: <h4>Below is a summary of people's opinions on the issue.</h4><hr><p>Here is a summary of the commen...\n",
      "  Comparison: <h4>Two summaries of opinions are shown below. Read carefully and answer according to your prior opi...\n",
      "\n",
      "Saved triplet data to: ../data_files/processed/sum_humanstudy_triplet_full.csv\n",
      "Total rows: 6750\n",
      "Total triplets: 2250\n",
      "✅ Perfect triplet structure: 2250 complete triplets\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the triplet_df structure first\n",
    "print(\"\\nDebugging triplet_df structure:\")\n",
    "print(f\"triplet_df shape: {triplet_df.shape}\")\n",
    "print(f\"triplet_df columns: {triplet_df.columns.tolist()}\")\n",
    "print(f\"First few rows:\")\n",
    "print(triplet_df.head())\n",
    "\n",
    "# Check if triplet_df is empty\n",
    "if len(triplet_df) == 0:\n",
    "    print(\"ERROR: triplet_df is empty! Check the matching process.\")\n",
    "else:\n",
    "    # Verify the triplet structure and show samples\n",
    "    print(\"\\nVerifying triplet structure:\")\n",
    "    if 'type' in triplet_df.columns:\n",
    "        print(f\"Question entries: {len(triplet_df[triplet_df['type'] == 'question'])}\")\n",
    "        print(f\"Rating entries: {len(triplet_df[triplet_df['type'] == 'rating'])}\")  \n",
    "        print(f\"Comparison entries: {len(triplet_df[triplet_df['type'] == 'comparison'])}\")\n",
    "        \n",
    "        # Show sample triplets\n",
    "        print(\"\\nSample triplet structure:\")\n",
    "        for i in range(0, min(9, len(triplet_df)), 3):\n",
    "            print(f\"\\nTriplet {i//3 + 1}:\")\n",
    "            print(f\"  Question: {triplet_df.iloc[i]['text']}\")\n",
    "            print(f\"  Rating: {triplet_df.iloc[i+1]['text'][:100]}...\")\n",
    "            if i+2 < len(triplet_df):\n",
    "                print(f\"  Comparison: {triplet_df.iloc[i+2]['text'][:100]}...\")\n",
    "    else:\n",
    "        print(\"ERROR: 'type' column missing from triplet_df\")\n",
    "\n",
    "# Save the triplet data\n",
    "output_path = '../data_files/processed/sum_humanstudy_triplet_full.csv'\n",
    "triplet_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved triplet data to: {output_path}\")\n",
    "print(f\"Total rows: {len(triplet_df)}\")\n",
    "print(f\"Total triplets: {len(triplet_df) // 3}\")\n",
    "\n",
    "# Final verification\n",
    "triplet_count = len(triplet_df) // 3\n",
    "remainder = len(triplet_df) % 3\n",
    "if remainder == 0:\n",
    "    print(f\"✅ Perfect triplet structure: {triplet_count} complete triplets\")\n",
    "else:\n",
    "    print(f\"⚠️ Incomplete triplets: {triplet_count} complete + {remainder} remaining entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_pair_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
