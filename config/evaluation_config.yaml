# Configuration file for summary evaluation

# Model configuration
model:
  name: "gpt-4o-mini"  # Model to use for evaluation
  system_prompt: "You are a helpful assistant"  # Default system prompt

# Evaluation settings
evaluation:
  # Summary is always generated from comments, not from question
  max_comments_per_dataset: null  # Limit number of comments to evaluate (null = all comments)
  save_detailed_results: true  # Save individual comment evaluation results
  save_summary_report: true  # Save overall summary report

# Output settings
output:
  directory: "evaluation_results"  # Directory to save results
  format: "txt"  # Output format (txt, json, csv)
  include_metadata: true  # Include file metadata in results

# Dataset settings
datasets:
  directory: "datasets"  # Directory containing JSON dataset files
  file_pattern: "*.json"  # Pattern to match dataset files
  exclude_files: []  # List of files to exclude from processing

# Processing settings
processing:
  parallel: false  # Process datasets in parallel (not recommended for API rate limits)
  batch_size: 1  # Number of datasets to process before saving results
  retry_failed: true  # Retry failed evaluations
  max_retries: 3  # Maximum number of retry attempts
